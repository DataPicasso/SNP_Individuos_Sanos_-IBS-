# **Iberian Peninsula Genome Data Processing**  

Este proyecto se centra en la extracci√≥n, procesamiento y transformaci√≥n de datos gen√≥micos de la **Fase 3 del Proyecto 1000 Genomas** de individuos sanos de la **Pen√≠nsula Ib√©rica**. Para manejar los grandes vol√∫menes de datos, se utiliz√≥ **Google Cloud Platform (GCP)** con una **m√°quina virtual (VM) basada en Ubuntu**, donde se ejecutaron herramientas especializadas como **bcftools** y **Python** para la manipulaci√≥n y estructuraci√≥n de los datos.  

La fuente de los datos utilizados en este proceso se encuentra en:  
üîó **[1000 Genomes Project Data](https://www.internationalgenome.org/data)**  

---

## **Caracter√≠sticas Principales**  
- **Extracci√≥n de Datos**: Descarga y extracci√≥n de millones de filas de datos gen√≥micos desde archivos **VCF (Variant Call Format)** almacenados en la nube.  
- **Procesamiento de Datos**: Limpieza, filtrado y transformaci√≥n de los datos crudos en formatos **CSV** para an√°lisis estructurados.  
- **Generaci√≥n de Data Individualizada**: Creaci√≥n de archivos CSV separados por paciente, facilitando el acceso y procesamiento de informaci√≥n espec√≠fica.  
- **Uso de Computaci√≥n en la Nube**: Se utiliz√≥ **GCP y Ubuntu VM** para manejar eficientemente el procesamiento de grandes vol√∫menes de datos gen√≥micos.  

---

## **Objetivos**  
‚úÖ **Estandarizar** y **estructurar** los datos gen√≥micos de la **Pen√≠nsula Ib√©rica** en un formato √≥ptimo para an√°lisis posteriores.  
‚úÖ **Aprovechar la computaci√≥n en la nube** para realizar un procesamiento eficiente de archivos **VCF** de gran tama√±o (~3GB por archivo).  
‚úÖ **Generar archivos individuales por paciente** a partir de un CSV consolidado, optimizando su manejo y consulta.  

---

## **Herramientas y Librer√≠as**  

### **Infraestructura**  
- **Google Cloud Platform (GCP)** ‚Üí Para el almacenamiento y procesamiento en la nube.  
- **M√°quina Virtual con Ubuntu** ‚Üí Necesaria para ejecutar **bcftools** y procesar archivos **VCF**.  

### **Lenguaje y Librer√≠as de Programaci√≥n**  
- **Python**  
  - `pandas` ‚Üí Manipulaci√≥n y estructuraci√≥n de datos.  
  - `numpy` ‚Üí Optimizaci√≥n de c√°lculos con datos num√©ricos.  
  - `csv` ‚Üí Escritura y lectura de archivos CSV.  
  - `json` ‚Üí Manejo de checkpoints y configuraci√≥n de procesos.  
  - `re` ‚Üí Expresiones regulares para validaci√≥n de genotipos.  
  - `subprocess` ‚Üí Ejecuci√≥n de comandos de Linux para manipular archivos VCF.  

### **Herramientas de Procesamiento de Datos Gen√≥micos**  
- **bcftools** ‚Üí Herramienta para la manipulaci√≥n y extracci√≥n de datos de archivos **VCF**.  
- **gzip** ‚Üí Descompresi√≥n de archivos gen√≥micos.  
- **gsutil** ‚Üí Manejo de archivos en Google Cloud Storage.  

---

## **Procedimiento de Extracci√≥n y Procesamiento de Datos**  

### **1Ô∏è‚É£ Extracci√≥n y Consolidaci√≥n de Datos**  
üìå **Archivo responsable:** `process_vcf.py`  
üìå **Funci√≥n principal:** Descargar y extraer informaci√≥n de archivos VCF.  

1. **Descarga los archivos VCF** desde Google Cloud Storage utilizando **gsutil**.  
2. **Filtra los pacientes ib√©ricos** para asegurar que los datos sean relevantes.  
3. **Utiliza `bcftools`** para extraer la informaci√≥n gen√≥mica y convertirla en un formato tabular (CSV).  
4. **Genera un archivo CSV consolidado** (`snp_individuals_data.csv`) que contiene la informaci√≥n de todos los pacientes seleccionados.  

---

### **2Ô∏è‚É£ Generaci√≥n de Archivos Individuales por Paciente**  
üìå **Archivo responsable:** `extractor1.py`  
üìå **Funci√≥n principal:** Dividir el CSV consolidado en archivos individuales por paciente.  

1. **Carga el archivo CSV consolidado** generado en la fase anterior.  
2. **Filtra los SNPs por cromosomas de inter√©s** y elimina columnas innecesarias.  
3. **Separa la informaci√≥n por paciente**, generando un archivo **CSV por cada individuo**.  
4. **Guarda y sube los archivos generados a Google Cloud Storage**.  

---

## **Instrucciones de Uso**  

### **Requisitos Previos**  
üìå **Configuraciones previas necesarias antes de ejecutar los scripts:**  

1. **Configurar una m√°quina virtual en Google Cloud Platform** con **Ubuntu**.  
2. **Instalar Python y sus dependencias:**  

   ```bash
   sudo apt update && sudo apt install -y python3 python3-pip bcftools gzip
   pip3 install pandas numpy google-cloud-storage
   ```

3. **Configurar Google Cloud SDK y autenticaci√≥n:**  

   ```bash
   gcloud auth application-default login
   ```

4. **Verificar que `bcftools` est√° correctamente instalado:**  

   ```bash
   bcftools --version
   ```

---

### **Ejecuci√≥n del Proceso Completo**  

#### **Paso 1: Ejecutar el script `process_vcf.py`**  
üìå **Objetivo:** Extraer informaci√≥n desde archivos VCF y generar un CSV consolidado.  

```bash
python3 process_vcf.py
```

üîπ **Resultado esperado:** Un archivo `snp_individuals_data.csv` con toda la informaci√≥n gen√≥mica consolidada.  

---

#### **Paso 2: Ejecutar el script `extractor1.py`**  
üìå **Objetivo:** Dividir el CSV consolidado en archivos individuales por paciente.  

```bash
python3 extractor1.py
```

üîπ **Resultado esperado:** M√∫ltiples archivos CSV en el bucket de GCP, cada uno correspondiente a un paciente espec√≠fico.  

---

### **Conclusi√≥n**  
Este flujo de trabajo permite transformar datos gen√≥micos crudos en formatos estructurados y organizados para an√°lisis posteriores. La combinaci√≥n de **Google Cloud Platform, Python y bcftools** garantiza un procesamiento eficiente de archivos **VCF** de gran tama√±o, optimizando el manejo de datos gen√≥micos a gran escala. üöÄ  

---

Si necesitas ajustes o m√°s detalles, dime y lo revisamos. üòä
